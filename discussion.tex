\section{Discussion}
Distributed machine learning is already seeing widespread use, and a variety of findings (both theoretical and practical) have been contributed to the field in recent years.

There is a noticeable gap between state-of-the-art systems that are found in traditional scientific literature, and implementations that are used in industry. While the scientific community is more focused on the theoretical limitations of distributed machine learning in aspects such as communication complexity and relative accuracy, industry systems have less regard for the theory behind the implentation. A good example of this is found in \citep{DistBelief2012}, which contains statements such as "[t]here is little theoretical grounding for the safety of these operations for nonconvex problems, but in practice we found relaxing consistency requirements to be remarkably effective". Compare this to e.g. \citep{Xing16} and its references, in which findings are evaluated within the context of theoretical optimality.

Practical application of distributed artificial neural networks is especially prevalent. State-of-the-art ANNs for complex conditional applications, such as the one described by \citet{Shazeer2017}, require optimizing tens of billions of parameters through tens of billions of samples, and make use of systems such as Tensorflow\citep{Tensorflow2015}\citep{Tensorflow2016} to distribute this process. Even networks of this scale, however, are generally trained on relatively small clusters (less than 100 machines) of powerful multi-GPU nodes. In comparison, computations on Google's deployment of MapReduce\citep{MapReduce} often use thousands of commodity worker machines.

The scale at which distributed ML currently occurs suggests one of two things: either effective ML models do not yet exist that can be efficiently distributed at big data scale, or current distribution methods have not advanced enough yet to support large-scale distributed ML. Improving either of these aspects is beneficial to the other: ML models that are more easily distributed require less advanced distribution mechanisms, whereas more versatile distribution mechanisms can compensate for less efficient ML algorithms. Which strategy will prove simpler to apply is not clear.